# âœï¸ Handwritten Manuscript Recognition (English + Kannada)

A modular implementation of a Swin Transformerâ€“based handwritten manuscript recognition model inspired by **Donut** â€” supporting **English and Kannada** characters.

This project is designed to be:

- ğŸ”§ configurable  
- ğŸ§© modular  
- ğŸš€ easy to train, test, and extend  

---

## ğŸ“ Project Structure

handwritten-recognition/
â”œâ”€â”€ config.yaml
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ train.py
â”œâ”€â”€ inference.py
â”œâ”€â”€ data/
â”‚ â”œâ”€â”€ init.py
â”‚ â”œâ”€â”€ tokenizer.py
â”‚ â””â”€â”€ dataset.py
â”œâ”€â”€ models/
â”‚ â”œâ”€â”€ init.py
â”‚ â”œâ”€â”€ encoder.py
â”‚ â”œâ”€â”€ decoder.py
â”‚ â””â”€â”€ model.py
â””â”€â”€ utils/
â”œâ”€â”€ init.py
â”œâ”€â”€ preprocessing.py
â”œâ”€â”€ metrics.py
â””â”€â”€ training.py

yaml
Copy code

---

## ğŸš€ Setup

```bash
python -m venv venv
source venv/bin/activate        # Linux/Mac
venv\Scripts\activate           # Windows

pip install -r requirements.txt

touch data/__init__.py models/__init__.py utils/__init__.py
ğŸ‹ï¸ Training
bash
Copy code
python train.py --config config.yaml
Resume training:

bash
Copy code
python train.py --config config.yaml
Monitor logs:

bash
Copy code
tail -f logs/training.log
ğŸ” Inference
bash
Copy code
python inference.py --checkpoint checkpoints/best_model.pth --image test.png
Batch directory:

bash
Copy code
python inference.py --checkpoint checkpoints/best_model.pth --image_dir images/
Save results:

bash
Copy code
python inference.py --checkpoint checkpoints/best_model.pth --image_dir images/ --output results.txt
Control decoding:

bash
Copy code
python inference.py --checkpoint checkpoints/best_model.pth --image test.png --temperature 0.7 --top_k 5
âš™ï¸ Quick config.yaml Edits
yaml
Copy code
data:
  train_path: "/your/path/here"
  batch_size: 4

training:
  epochs: 100
  learning_rate: 3e-4
ğŸ’¡ Reduce batch_size if GPU runs out of memory.

ğŸ› Common Fixes
bash
Copy code
touch data/__init__.py models/__init__.py utils/__init__.py
pip install -r requirements.txt
Check dataset path in config.yaml.

If CUDA error â†’ lower batch size.

ğŸ“Š Metrics
Metric	Meaning	Good	Needs Work
Loss	Model error	< 0.5	> 2.0
Accuracy	Correct outputs	> 90%	< 50%
CER	Character Error Rate	< 5%	> 20%

ğŸ“‚ Important Outputs
bash
Copy code
checkpoints/best_model.pth
logs/training.log
checkpoints/config.yaml
ğŸ”„ Typical Workflow
bash
Copy code
pip install -r requirements.txt
nano config.yaml

python train.py --config config.yaml
tail -f logs/training.log

python inference.py --checkpoint checkpoints/best_model.pth --image test.png
ğŸ›  Troubleshooting
bash
Copy code
cat logs/training.log
ls /path/to/dataset/training_images/
nvidia-smi

python -c "from data.tokenizer import CharTokenizer; print('OK')"
python -c "from models.model import HandwrittenDonut; print('OK')"
ğŸ¯ Performance Tuning
yaml
Copy code
data:
  batch_size: 16
  num_workers: 4

training:
  epochs: 100
  early_stopping_patience: 20

model:
  decoder_layers: 4
  decoder_heads: 8
ğŸ’¾ Checkpoint Management
bash
Copy code
# Best model
checkpoints/best_model.pth

# Resume specific checkpoint
# resume_from: "checkpoints/checkpoint_epoch_20.pth"

# Clean extras
rm checkpoints/checkpoint_epoch_*.pth
âœ… Notes
Always run inference using best_model.pth

Keep __init__.py files (imports break otherwise)

Validate on a separate dataset

Use nvidia-smi to watch GPU
