# Swin-TransformerHandwritten Donut â€” English + Kannada OCR (Swin Transformer)

This project implements a lightweight OCR model for handwritten text using:

Swin Transformer as the visual encoder

A custom Transformer decoder

A character-level tokenizer supporting English + Kannada

Built-in manuscript preprocessing (CLAHE, denoising, adaptive thresholding, morphology)

The model learns to predict the label name of each image (one character token at a time) based on folder names.

âœ¨ Features

âœ”ï¸ Works on handwritten manuscripts

âœ”ï¸ Internal noise removal & contrast enhancement

âœ”ï¸ Character tokenizer (English + Kannada)

âœ”ï¸ Simple dataset structure

âœ”ï¸ Trainable end-to-end

âœ”ï¸ Easy inference on new images

ğŸ“‚ Dataset Structure

Place your images like this:

dataset/
 â””â”€â”€ training_images/
      â”œâ”€â”€ apple/
      â”‚    â”œâ”€â”€ img1.jpg
      â”‚    â”œâ”€â”€ img2.png
      â”‚
      â”œâ”€â”€ à²…à²®à³à²®/
      â”‚    â”œâ”€â”€ img3.jpg
      â”‚    â”œâ”€â”€ img4.png
      â”‚
      â””â”€â”€ hello/
           â”œâ”€â”€ img5.jpg
           â”œâ”€â”€ img6.png


ğŸ‘‰ Folder name = label text (what the model learns to predict)

ğŸ”§ Installation

Install dependencies:

pip install transformers timm torchvision pillow opencv-python

â–¶ï¸ Training

Run the script:

python train.py


What happens during training:

Images are resized to 224Ã—224

Preprocessing improves readability (denoise, CLAHE, threshold)

Images go through Swin Transformer encoder

Transformer decoder predicts characters

Cross-Entropy loss updates weights

Training runs for 10 epochs by default.

ğŸ” Inference (Prediction)

Use the predict() function:

predict("/content/test_image.jpg")


Example output:

Prediction: hello

ğŸ§  Model Architecture
Component	Role
Swin Transformer	Extracts visual features
Transformer Decoder	Generates text tokens
Character Tokenizer	Maps English + Kannada characters
Manuscript Preprocessing	Improves readability
ğŸ§¾ Tokenizer Details

Special tokens:

Token	Meaning
<pad>	padding
<s>	start
</s>	end
<unk>	unknown

Both English letters and Kannada characters are supported.

âœï¸ Preprocessing Pipeline

The script automatically performs:

Grayscale conversion

Noise removal (fastNlMeans)

CLAHE contrast boost

Adaptive thresholding

Morphological opening (remove artifacts)

This improves OCR accuracy on noisy manuscripts.

âš™ï¸ Hyperparameters
Parameter	Value
Optimizer	AdamW
LR	3e-4
Batch Size	8
Loss	CrossEntropy (ignore pad)
Epochs	10
ğŸ’¡ Notes & Tips

More data = better accuracy

Keep handwriting centered & cropped

Balance classes (avoid one label dominating)

Increase epochs if loss is still high

ğŸ“Œ Future Improvements (Optional)

Beam search decoding

Multi-line text handling

Dataset augmentation

Save / load trained weights

ğŸ› ï¸ Requirements

Python 3.8+

GPU recommended (but CPU works)

PyTorch + Transformers

ğŸ“œ License

Use freely for research, learning, and educational projects.
